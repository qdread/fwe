# Clean version of waste tracking analysis (without plots and without Rmd)
# V2.0: Change the way numbers of establishments are calculated
# QDR / FWE / 03 Mar 2020

# In this new version, instead of using proportions of receipts, use the # of foodservice contractors as the establishments
# But use the total amounts of food purchased by "eligible" industries, as identified by Steve, as the potential food that can be affected

# Load data ---------------------------------------------------------------



# Load packages and check whether this is being run locally or on rstudio server.
library(tidyverse)
library(reticulate)
library(directlabels)

is_local <- dir.exists('Q:/')
fp <- ifelse(is_local, 'Q:', '/nfs/qread-data')
fp_github <- file.path(ifelse(is_local, '~/Documents/GitHub', '~'))

# Load numbers of establishments by NAICS
susb_naics <- read_csv(file.path(fp, 'csv_exports/SUSB_NAICS_allvariables.csv'))
# Load the BEA code data (erroneously called NAICS)
bea_codes <- read_csv(file.path(fp, 'crossreference_tables/naics_crosswalk_final.csv'))
# Load NAICS BEA crosswalks
load(file.path(fp, 'crossreference_tables/NAICS_BEA_SCTG_crosswalk.RData'))
bea_naics <- read_csv(file.path(fp, 'crossreference_tables/BEA_NAICS07_NAICS12_crosswalk.csv'))
# Load LAFA
source(file.path(fp_github, 'fwe/read_data/read_lafa.r'))
lafa <- list(dairy, fat, fruit, grain, meat, sugar, veg)


# Set assumptions ---------------------------------------------------------

# Edit 27 March 2020: Convert all costs to 2012 dollars.

cost_range <- c(lower = 7934, upper = 17435) # Lower and upper bounds for annual cost, based on percentiles for employee hourly wages.

waste_reduction <- c(lower = 0.4, upper = 0.5, mode = 0.45) # Waste reduction achievable, rates from ReFED?

prop_kitchen_waste <- c(lower = 0.7, upper = 0.97, mode = 0.85) # Proportion kitchen waste (all other than plate waste), estimated from a few sources

equipment_costs <- c(lower = 405, upper = 1012) # Lower and upper bounds for annual equipment costs
# This is based on the $2000 to $5000 range of initial equipment purchase, annualized and converted to 2012 dollars.

# Overall waste reduction is going to be the proportion kitchen waste reduction you can get from WTA * the proportion of food waste that is in the kitchen versus "plate waste" generated by the customers

# This is going to be the same for all. We will use the "mode"
# Edit 24 March 2020: Use the lower and upper bounds of each waste reduction component to get the uncertainty for impact reduction
overall_waste_reduction <- prop_kitchen_waste * waste_reduction

# Subsets of industries to target -----------------------------------------

codes_subset <- bea_codes %>% filter(stage %in% c('foodservice', 'institutional')) %>% select(BEA_389_code, BEA_389_def)

restaurants <- codes_subset$BEA_389_code[1:3]
tourism_hospitality <- codes_subset$BEA_389_code[c(4,6,9, 12, 13, 14, 15, 16, 17, 18)] # Include promoters/agents (arena operators) Include air and ships. Exclude movies and performances.
institutions <- codes_subset$BEA_389_code[c(19, 20, 22:27)] # Leave out other educational services.

# 3 codes represent restaurants, 10 represent tourism/hospitality industry, 8 represent institutions that could adopt "WTA"

bea_to_use_df <- data.frame(BEA_Code = c(restaurants, tourism_hospitality, institutions),
                            sector = rep(c('restaurants', 'tourism and hospitality', 'institutions'), c(length(restaurants), length(tourism_hospitality), length(institutions))))

bea_naics_to_use <- bea_to_use_df %>% left_join(bea_naics)
# any(duplicated(bea_naics_to_use$related_2012_NAICS_6digit)) # There are no duplicates. 83 unique NAICS codes.

# Create subset with only food service.
susb_naics_foodservice <- bea_naics_to_use %>%
  select(BEA_Code, BEA_Title, sector, related_2012_NAICS_6digit) %>%
  rename(NAICS = related_2012_NAICS_6digit) %>%
  left_join(susb_naics)

# Flag rows that aren't going to be used (for example, freight transportation industries within transportation codes)
# Also remove campgrounds within the hospitality industry.
# unique(susb_naics_foodservice$`NAICS description`)
words_to_remove <- c('Freight', 'Nonscheduled', 'Air Traffic', 'Support Activities', 'Port', 'Cargo', 'Navigational', 'Towing', 'Packing', 'Campground')

susb_naics_foodservice <- susb_naics_foodservice %>%
  mutate(use = !grepl(paste(words_to_remove, collapse = '|'), `NAICS description`),
         `Size class` = factor(`Size class`, levels = c('fewer than 20', '20 to 99', '100 to 499', 'more than 500', 'total')))

#####
# New way of getting institutions. Use primary food service operations, and contractors/caterers.

restaurant_naics <- c(722511, 722513, 722514, 722515, 722330, 722410)
contractor_naics <- c(722310, 722320)

susb_naics_foodservice <- susb_naics_foodservice %>%
  mutate(category = case_when(NAICS %in% restaurant_naics ~ 'restaurant',
                              NAICS %in% contractor_naics ~ 'contractor',
                              TRUE ~ 'other')) 

# Sum up establishments by size class in the two large categories
# Assume all contractors/caterers can adopt, but only restaurants with >= 20 employees can adopt.

susb_food_sums <- susb_naics_foodservice %>%
  group_by(category, `Size class`) %>%
  summarize_at(vars(`No. firms`:`Total receipts`), sum) %>%
  filter(!is.na(`Size class`), !`Size class` %in% 'total')


# What are the proportions

susb_food_cumul_prop <- susb_food_sums %>%
  mutate_at(vars(`No. firms`:`Total receipts`), ~ cumsum(.x) / sum(.x))

####
# We need two different sets of totals. 
# 1. The total number of establishments that implement leanpath (for costs). 
# --- This equals the number of restaurants >=20 employees
# --- Plus the number of foodservice contractors (other food and drinking estbs with bars and food trucks removed)
# 2. The proportion of food purchases in industries that contract foodservice operators, that are affected by WTA implementation. 
# --- We will assume that this is the % of purchases made by size class >= 20 employees.
# --- Also, we assume that inputs are proportional to receipts.
# --- So this would exclude the small operations for all industries EXCEPT those listed as contractors

# 1. establishments that can implement
establishments_implementing <- susb_naics_foodservice %>%
  filter(!category %in% 'other') %>%
  group_by(category, BEA_Code, NAICS, `NAICS description`, `Size class`) %>%
  summarize_at(vars(`No. firms`:`Total receipts`), sum) %>%
  select(-`No. employees`, -`Total payroll`) %>% 
  filter(!`Size class` %in% 'total') %>%
  mutate(can_implement = category == 'contractor' | category == 'restaurant' & `Size class` != 'fewer than 20')
    
# establishments_implementing %>% print(n = nrow(.))

establishments_implementing_total <- establishments_implementing %>%
  group_by(category, BEA_Code, can_implement) %>%
  summarize(n_estab = sum(`No. establishments`))



# size_classes_exclude <- expand_grid(sector = c('restaurants', 'tourism and hospitality', 'institutions'), `Size class` = levels(susb_food_sums$`Size class`)[1:4]) %>%
#   mutate(exclude = `Size class` %in% c('fewer than 20'))

# Within each BEA code, get the percentage of total receipts that will be affected by WTA implementation
# All establishments with >20 employees, and also account for the fact that some tourism and hospitality BEA codes contain NAICS codes that aren't going to adopt WTA

susb_bea_food_sums <- susb_naics_foodservice %>%
  mutate(sector = if_else(category == 'contractor', 'contractors', as.character(sector))) %>%
  group_by(sector, BEA_Code, BEA_Title, use, `Size class`) %>%
  summarize_at(vars(`No. firms`:`Total receipts`), sum) %>%
  filter(!is.na(`Size class`), !`Size class` %in% 'total')



# Impute missing values ---------------------------------------------------

recbyestb <- susb_bea_food_sums %>%
  filter(use) %>%
  mutate(empl_per_firm = `No. employees`/`No. firms`,
         receipts_per_estb = `Total receipts`/`No. establishments`,
         receipts_per_firm = `Total receipts`/`No. firms`) 

# Impute the air transit number.
lm_air <- lm(log(receipts_per_firm) ~ log(empl_per_firm), data = recbyestb, subset = BEA_Title == 'Air transportation' & receipts_per_firm > 0)

predicted_air <- exp(predict(lm_air, newdata = recbyestb %>% filter(BEA_Title == 'Air transportation') %>% select(empl_per_firm)))
# predicted_air[4] # The imputed value for air transportation total receipts for firms with 500 or more employees.

# For water transportation, our problem is that we don't know either the average number of employees per firm or the receipts, the employees were
# also clearly censored wince only 202 employees for 11 firms is a lot less than 500 per firm. 
# Let's look for a similar industry to see whether we can get a number of employees per firm to use to impute.
lm_water <- lm(log(receipts_per_firm) ~ log(empl_per_firm), data = recbyestb, subset = BEA_Title == 'Water transportation' & receipts_per_firm > 0)

# We will use the number from scenic transportation (700) which seems fairly conservative
# This number can be sampled from in an uncertainty analysis too.
recbyestb %>% filter(BEA_Title == 'Water transportation') %>% mutate(empl_per_firm = if_else(`Size class` == 'more than 500', 700, empl_per_firm)) %>% select(empl_per_firm)
predicted_water <- exp(predict(lm_water, newdata = recbyestb %>% filter(BEA_Title == 'Water transportation') %>% mutate(empl_per_firm = if_else(`Size class` == 'more than 500', 700, empl_per_firm)) %>% select(empl_per_firm)))
exp(predict(lm_water))

# Create new imputed dataset.
susb_bea_food_sums[susb_bea_food_sums$BEA_Code %in% c('481000', '483000') & susb_bea_food_sums$use & susb_bea_food_sums$`Size class` %in% 'more than 500', "Total receipts"] <- c(predicted_air[4], predicted_water[4])


# Get final proportions affected ------------------------------------------

# The second type of sum:
# 2. sum up the non-excluded number of receipts in each industry so that food bought by very small firms isn't eligible for waste reduction
#### Here are the proportions of receipts that will be affected by adoption of WTA

sums_by_affected <- susb_bea_food_sums %>%
  ungroup %>%
  mutate(use = `Size class` != 'fewer than 20' | sector == 'contractors') %>%
  group_by(sector, BEA_Code, BEA_Title, use) %>%
  summarize_at(vars(`No. firms`:`Total receipts`), sum)

# Sum up again so that the other food and drinking places is included.
sums_by_affected_final <- susb_bea_food_sums %>%
  ungroup %>%
  mutate(use = `Size class` != 'fewer than 20' | sector == 'contractors') %>%
  group_by(BEA_Code, BEA_Title, use) %>%
  summarize_at(vars(`No. firms`:`Total receipts`), sum)



susb_bea_proportion_affected <- sums_by_affected_final %>%
  select(-(`No. firms`:`Total payroll`)) %>%
  pivot_wider(names_from = use, values_from = `Total receipts`, values_fill = list(`Total receipts` = 0), names_prefix = 'receipts_') %>%
  mutate(proportion = receipts_TRUE / (receipts_TRUE + receipts_FALSE))

  

# susb_bea_proportion_affected <- susb_bea_food_sums %>% 
#   ungroup %>%
#   left_join(size_classes_exclude) %>%
#   mutate(use = use & !exclude) %>%
#   group_by(sector, BEA_Code, BEA_Title) %>%
#   summarize(proportion_receipts_affected = sum(`Total receipts`[!exclude])/sum(`Total receipts`))

# # Now multiply this by "proportion food" for each of the industries
# prop_foods <- bea_codes %>%
#   select(BEA_389_code, proportion_food) %>%
#   rename(BEA_Code = BEA_389_code)

#proportion_affected <- susb_bea_proportion_affected %>% left_join(prop_foods) %>% mutate(final_proportion = proportion_receipts_affected * proportion_food)

# We also need number of establishments affected so we can get the total annual cost
# establishments_affected <- susb_bea_food_sums %>% 
#   ungroup %>%
#   left_join(size_classes_exclude) %>%
#   mutate(use = use & !exclude) %>%
#   group_by(sector, BEA_Code, BEA_Title, use) %>%
#   summarize(establishments = sum(`No. establishments`))


# Load data for waste rate calc -------------------------------------------

# BEA levels 1+3 to 4+6+7+8 is already subsetted from an older analysis I did.
food_U <- read.csv(file.path(fp, 'crossreference_tables/level13_to_level4678_inputs.csv'), row.names = 1, check.names = FALSE)

# Mapping will need to go bea --> qfahpd --> lafa
# Load the two necessary crosswalks.
bea2qfahpd <- read_csv(file.path(fp, 'crossreference_tables/bea_qfahpd_crosswalk.csv'))
qfahpd2lafa <- read_csv(file.path(fp, 'crossreference_tables/qfahpd_lafa_crosswalk.csv'))

# Also load the QFAHPD data so that we can get the prices.
qfahpd2 <- read_csv(file.path(fp, 'raw_data/USDA/QFAHPD/tidy_data/qfahpd2.csv'))

# Read the description of LAFA's nested category structure in.
lafa_struct <- read_csv(file.path(fp, 'crossreference_tables/lafa_category_structure.csv'))

# Demand codes table to convert 6 digit codes to the ones used by USEEIO
all_codes <- read_csv(file.path(fp, 'crossreference_tables/all_codes.csv'))

# Get rid of unneeded rows and columns
food_U <- food_U[, susb_bea_proportion_affected$BEA_Code]
food_U <- food_U[rowSums(food_U) > 0, ]

# Beverage codes should be removed.
beveragecodes <- c('311920','311930','312110','312120','312130','312140')
food_U <- food_U[!row.names(food_U) %in% beveragecodes, ]


# Map BEA to QFAHPD -------------------------------------------------------

# Convert the comma-separated string columns to list columns.
bea2qfahpd <- bea2qfahpd %>%
  mutate(QFAHPD_code = strsplit(QFAHPD_code, ';'))
qfahpd2lafa <- qfahpd2lafa %>%
  mutate(LAFA_names = strsplit(LAFA_names, ';'))

# Do the mapping of food_U to QFAHPD codes.
food_U_QFAHPD <- food_U %>%
  mutate(BEA_389_code = row.names(food_U)) %>%
  pivot_longer(-BEA_389_code, names_to = 'BEA_recipient_code', values_to = 'monetary_flow') %>%
  left_join(bea2qfahpd %>% select(-BEA_389_def)) %>%
  group_by(BEA_389_code, BEA_recipient_code) %>%
  group_modify(~ data.frame(QFAHPD_code = .$QFAHPD_code[[1]], monetary_flow = .$monetary_flow/length(.$QFAHPD_code[[1]])))

# Now we have the use table where each BEA code has multiple rows for the different QFAHPD codes that make it up
# Create an aggregated version of QFAHPD to get the final price values for each code
# Weighted average across all market groups, years, and quarters
qfahpd_agg <- qfahpd2 %>%
  group_by(foodgroup) %>%
  summarize(price = weighted.mean(price, aggweight, na.rm = TRUE))

# Join the aggregated QFAHPD back up with its numerical codes and LAFA names
# Meanwhile correct a couple wrong names in the dairy category
qfahpd_agg <- qfahpd_agg %>% 
  mutate(foodgroup = gsub('Whole and 2%', 'Regular fat', foodgroup)) %>%
  left_join(qfahpd2lafa, by = c('foodgroup' = 'QFAHPD_name')) %>%
  mutate(QFAHPD_code = as.character(QFAHPD_code))

# Now join the aggregated QFAHPD with the food_U mapped to QFAHPD so that the total $ can be divided by $/weight to yield a weight (or mass).
# The units mass is in don't matter since they are all relative
food_U_LAFA <- food_U_QFAHPD %>%
  left_join(qfahpd_agg) %>%
  mutate(mass_flow = monetary_flow / price)


# Get LAFA rates including lower-level averages ---------------------------

# For the unique LAFA names in the QFAHPD to LAFA mapping, extract the waste rates for 2012 or the closest year post-2012.
lafa_to_extract <- Reduce(union, qfahpd2lafa$LAFA_names)

# Split it up again by LAFA so that we can get the weights.
# Get only the columns we care about from each LAFA element in the list
# Then get the year closest to 2012
lafa_df <- lafa %>% 
  map_dfr(~ select(., Category, Year, Loss_at_consumer_level_Other__cooking_loss_and_uneaten_food__Percent, Consumer_weight_Lbs.year)) %>%
  rename(avoidable_consumer_loss = Loss_at_consumer_level_Other__cooking_loss_and_uneaten_food__Percent,
         consumer_weight = Consumer_weight_Lbs.year) %>%
  filter(!is.na(avoidable_consumer_loss)) %>%
  group_by(Category) %>%
  summarize(avoidable_consumer_loss = avoidable_consumer_loss[which.min(abs(Year-2012))],
            consumer_weight = consumer_weight[which.min(abs(Year-2012))])

# Use nested category structure to get weighted mean rates for the coarser LAFA groups
# for QFAHPD foods that do not resolve to the finest available level of LAFA
lafa_df <- lafa_df %>%
  left_join(lafa_struct, by = c('Category' = 'Food'))

lafa_group_rates <- map_dfr(1:4, function(i) lafa_df %>% 
                              rename_(subgroup = paste0('subgroup', i)) %>%
                              group_by(subgroup) %>% 
                              summarize(avoidable_consumer_loss = weighted.mean(x = avoidable_consumer_loss, w = consumer_weight))) %>%
  filter(!is.na(subgroup))

# Use LAFA overall mean for prepared food in the "other" category
overall_mean <- with(lafa_df, weighted.mean(avoidable_consumer_loss, consumer_weight))

all_lafa_rates <- data.frame(Category = c(lafa_df$Category, lafa_group_rates$subgroup, 'prepared food'),
                             avoidable_consumer_loss = c(lafa_df$avoidable_consumer_loss, lafa_group_rates$avoidable_consumer_loss, overall_mean))


# Map mass flows to LAFA, convert back to $ -------------------------------

# Use the same pipe as last time to spread out the LAFA names over the rows

food_U_LAFA_spread <- food_U_LAFA %>%
  group_by(BEA_389_code, BEA_recipient_code, QFAHPD_code, price) %>%
  group_modify(~ data.frame(LAFA_name = .$LAFA_names[[1]], 
                            mass_flow = .$mass_flow/length(.$LAFA_names[[1]]),
                            monetary_flow = .$monetary_flow/length(.$LAFA_names[[1]]))) %>%
  left_join(all_lafa_rates, by = c('LAFA_name' = 'Category'))

# Join with the proportion of sales affected (also the same as proportion of mass affected) based on % sales that are food and the >20 employee threshold
# Then calculate the reduction in required mass flow for each food type, and then a weighted average to get the reduction in monetary flow needed
demand_change_fn <- function(W0, r, p) p * ((1 - W0) / (1 - (1 - r) * W0) - 1) + 1

food_U_LAFA_spread <- food_U_LAFA_spread %>% 
  left_join(susb_bea_proportion_affected, by = c('BEA_recipient_code' = 'BEA_Code')) %>%
  mutate(reduction_by_mass_mean = demand_change_fn(W0 = avoidable_consumer_loss/100, r = overall_waste_reduction['mode'], p = proportion),
         reduction_by_mass_lower = demand_change_fn(W0 = avoidable_consumer_loss/100, r = overall_waste_reduction['lower'], p = proportion),
         reduction_by_mass_upper = demand_change_fn(W0 = avoidable_consumer_loss/100, r = overall_waste_reduction['upper'], p = proportion),
         mass_flow_post_intervention_mean = mass_flow * reduction_by_mass_mean,
         mass_flow_post_intervention_lower = mass_flow * reduction_by_mass_lower,
         mass_flow_post_intervention_upper = mass_flow * reduction_by_mass_upper,
         monetary_flow_post_intervention_mean = mass_flow_post_intervention_mean * price,
         monetary_flow_post_intervention_lower = mass_flow_post_intervention_lower * price,
         monetary_flow_post_intervention_upper = mass_flow_post_intervention_upper * price)

# Sum up by old row and column index from the original food_U matrix, then reshape to make the same matrix.
# Do this for the mean, upper, and lower bounds.
#### mean
food_U_postintervention_df <- food_U_LAFA_spread %>%
  group_by(BEA_389_code, BEA_recipient_code) %>%
  summarize(monetary_flow = sum(monetary_flow_post_intervention_mean, na.rm = TRUE)) 

food_U_postintervention <- food_U_postintervention_df %>%
  pivot_wider(names_from = BEA_recipient_code, values_from = monetary_flow, values_fill = list(monetary_flow = 0)) %>%
  as.data.frame
row.names(food_U_postintervention) <- food_U_postintervention$BEA_389_code
food_U_postintervention <- food_U_postintervention[, !names(food_U_postintervention) %in% 'BEA_389_code']

# Make the row and column order the same as food_U
food_U_postintervention <- food_U_postintervention[, names(food_U)]

#### lower
food_U_postintervention_df_lower <- food_U_LAFA_spread %>%
  group_by(BEA_389_code, BEA_recipient_code) %>%
  summarize(monetary_flow = sum(monetary_flow_post_intervention_lower, na.rm = TRUE)) 

food_U_postintervention_lower <- food_U_postintervention_df_lower %>%
  pivot_wider(names_from = BEA_recipient_code, values_from = monetary_flow, values_fill = list(monetary_flow = 0)) %>%
  as.data.frame
row.names(food_U_postintervention_lower) <- food_U_postintervention_lower$BEA_389_code
food_U_postintervention_lower <- food_U_postintervention_lower[, !names(food_U_postintervention_lower) %in% 'BEA_389_code']

# Make the row and column order the same as food_U
food_U_postintervention_lower <- food_U_postintervention_lower[, names(food_U)]

#### upper
food_U_postintervention_df_upper <- food_U_LAFA_spread %>%
  group_by(BEA_389_code, BEA_recipient_code) %>%
  summarize(monetary_flow = sum(monetary_flow_post_intervention_upper, na.rm = TRUE)) 

food_U_postintervention_upper <- food_U_postintervention_df_upper %>%
  pivot_wider(names_from = BEA_recipient_code, values_from = monetary_flow, values_fill = list(monetary_flow = 0)) %>%
  as.data.frame
row.names(food_U_postintervention_upper) <- food_U_postintervention_upper$BEA_389_code
food_U_postintervention_upper <- food_U_postintervention_upper[, !names(food_U_postintervention_upper) %in% 'BEA_389_code']

# Make the row and column order the same as food_U
food_U_postintervention_upper <- food_U_postintervention_upper[, names(food_U)]

# Summarize $ and mass flow changes ---------------------------------------

# The % of waste reduced by mass won't be exactly equivalent to the % of waste reduced by $.

postintervention <- food_U_postintervention_df %>%
  group_by(BEA_recipient_code) %>%
  summarize(monetary_flow_postintervention = sum(monetary_flow))

postintervention_lower <- food_U_postintervention_df_lower %>%
  group_by(BEA_recipient_code) %>%
  summarize(monetary_flow_postintervention = sum(monetary_flow))

postintervention_upper <- food_U_postintervention_df_upper %>%
  group_by(BEA_recipient_code) %>%
  summarize(monetary_flow_postintervention = sum(monetary_flow))

postintervention_all <- cbind(postintervention, 
                              monetary_flow_postintervention_lower = postintervention_lower$monetary_flow_postintervention,
                              monetary_flow_postintervention_upper = postintervention_upper$monetary_flow_postintervention)

preintervention <- data.frame(BEA_recipient_code = names(food_U), monetary_flow_preintervention = colSums(food_U))

monetary_byintervention <- left_join(postintervention_all, preintervention) %>%
  mutate(reduction_bydollar = 1 - monetary_flow_postintervention / monetary_flow_preintervention,
         reduction_bydollar_lower = 1 - monetary_flow_postintervention_lower / monetary_flow_preintervention,
         reduction_bydollar_upper = 1 - monetary_flow_postintervention_upper / monetary_flow_preintervention) 

mass_byintervention <- food_U_LAFA_spread %>%
  group_by(BEA_recipient_code) %>%
  summarize(mass_flow_preintervention = sum(mass_flow, na.rm = TRUE),
            mass_flow_postintervention = sum(mass_flow_post_intervention_mean, na.rm = TRUE),
            mass_flow_postintervention_lower = sum(mass_flow_post_intervention_lower, na.rm = TRUE),
            mass_flow_postintervention_upper = sum(mass_flow_post_intervention_upper, na.rm = TRUE)) %>%
  mutate(reduction_bymass = 1 - mass_flow_postintervention / mass_flow_preintervention,
         reduction_bymass_lower = 1 - mass_flow_postintervention_lower / mass_flow_preintervention,
         reduction_bymass_upper = 1 - mass_flow_postintervention_upper / mass_flow_preintervention) 

rate_changes <- left_join(mass_byintervention, monetary_byintervention)

# A better way is to phrase it as reducing the operating costs (purchases of raw materials) by the affected industries
# Since we have a waste rate reduction by mass, convert it back to waste rate reduction by money and get the purchasing rate reduction from each of the industries that supply the final foodservice industries.

# Calculate pre and post incoming monetary food flow in millions of dollars
total_prepost <- data.frame(BEA_Code = names(food_U),
                            food_purchases_baseline = colSums(food_U),
                            food_purchases_postintervention = colSums(food_U_postintervention),
                            food_purchases_postintervention_lower = colSums(food_U_postintervention_lower),
                            food_purchases_postintervention_upper = colSums(food_U_postintervention_upper)) %>%
  mutate(reduction = food_purchases_baseline - food_purchases_postintervention,
         reduction_lower = food_purchases_baseline - food_purchases_postintervention_lower,
         reduction_upper = food_purchases_baseline - food_purchases_postintervention_upper)


# Calculate baseline waste by industry ------------------------------------

# Weighted mean of waste rate by mass flow for each foodservice industry = final waste rate for the industries!
baseline_waste_foodservice <- food_U_LAFA_spread %>%
  group_by(BEA_recipient_code) %>%
  summarize(avoidable_consumer_loss = weighted.mean(x = avoidable_consumer_loss, w = mass_flow, na.rm = TRUE))

# Join up the names of the BEA codes and print the table of values
baseline_waste_foodservice <- baseline_waste_foodservice %>% 
  left_join(codes_subset, by = c('BEA_recipient_code' = 'BEA_389_code')) %>%
  setNames(c('BEA_Code', 'baseline', 'BEA_Title')) 

baseline_waste_foodservice <- baseline_waste_foodservice %>%
  left_join(susb_bea_proportion_affected %>% ungroup %>% select(BEA_Code, proportion)) %>%
  left_join(total_prepost)

# Above they were marginal column totals for the recipient industries
# Phrase it also as marginal row totals for the food types

reduction_byfoodtype <- data.frame(BEA_Code = row.names(food_U),
                                   cost_averted = rowSums(food_U) - rowSums(food_U_postintervention),
                                   cost_averted_lower = rowSums(food_U) - rowSums(food_U_postintervention_lower),
                                   cost_averted_upper = rowSums(food_U) - rowSums(food_U_postintervention_upper))

# Edit. Run for full service, limited service, and contractors separately. Sum up all the purchases for tourism & institutions to get contractors' food purchases.

fullsvc_codes <- c("722110")
limitedsvc_codes <- c("722A00", "722211")

food_U_bygroup <- data.frame(full_service_restaurants = food_U[, fullsvc_codes],
                             limited_mobile_and_bars = rowSums(food_U[, limitedsvc_codes]),
                             contracted_foodservice = rowSums(food_U[, !names(food_U) %in% c(fullsvc_codes, limitedsvc_codes)]))


food_U_bygroup_postintervention <- data.frame(full_service_restaurants = food_U_postintervention[, fullsvc_codes],
                                              limited_mobile_and_bars = rowSums(food_U_postintervention[, limitedsvc_codes]),
                                              contracted_foodservice = rowSums(food_U_postintervention[, !names(food_U_postintervention) %in% c(fullsvc_codes, limitedsvc_codes)]))

food_U_bygroup_postintervention_lower <- data.frame(full_service_restaurants = food_U_postintervention_lower[, fullsvc_codes],
                                              limited_mobile_and_bars = rowSums(food_U_postintervention_lower[, limitedsvc_codes]),
                                              contracted_foodservice = rowSums(food_U_postintervention_lower[, !names(food_U_postintervention_lower) %in% c(fullsvc_codes, limitedsvc_codes)]))

food_U_bygroup_postintervention_upper <- data.frame(full_service_restaurants = food_U_postintervention_upper[, fullsvc_codes],
                                              limited_mobile_and_bars = rowSums(food_U_postintervention_upper[, limitedsvc_codes]),
                                              contracted_foodservice = rowSums(food_U_postintervention_upper[, !names(food_U_postintervention_upper) %in% c(fullsvc_codes, limitedsvc_codes)]))

# Run EEIO ----------------------------------------------------------------



# Simply enough, just run it on the difference in the two rowSums for pre and post intervention
# This represents final operating costs of the industries, as if it were final consumer demand
if (!is_local) use_python('/usr/bin/python3')
source_python(file.path(fp_github, 'fwe/USEEIO/eeio_lcia.py'))

# Match row names of food_U with longer codes that eeio_lcia() will recognize
demand_codes <- as.list(all_codes$sector_desc_drc[match(rownames(food_U), all_codes$sector_code_uppercase)])

# The model is already built so we don't need to build it again. 
# All we need to do is match the demand vector 6 digit codes with the codes that include the full names
# then run eeio_lcia on it.
# Do for each of the 3 groups separately

eeio_wta_baseline_bygroup <- map(food_U_bygroup, ~ eeio_lcia('USEEIO2012', as.list(. * 1e6), demand_codes)) 
eeio_wta_averted_bygroup <- map(food_U_bygroup - food_U_bygroup_postintervention, ~ eeio_lcia('USEEIO2012', as.list(. * 1e6), demand_codes)) 
eeio_wta_averted_bygroup_lower <- map(food_U_bygroup - food_U_bygroup_postintervention_lower, ~ eeio_lcia('USEEIO2012', as.list(. * 1e6), demand_codes)) 
eeio_wta_averted_bygroup_upper <- map(food_U_bygroup - food_U_bygroup_postintervention_upper, ~ eeio_lcia('USEEIO2012', as.list(. * 1e6), demand_codes)) 

# Combine into a data frame
eeio_dat_bygroup <- data.frame(group = c('full-service restaurants',
                                         'limited-service restaurants, mobile foodservice, and bars',
                                         'contracted foodservice operations')) %>%
  mutate(category = map(eeio_wta_baseline_bygroup, row.names),
         baseline = map(eeio_wta_baseline_bygroup, 1),
         impact_averted = map(eeio_wta_averted_bygroup, 1),
         impact_averted_lower = map(eeio_wta_averted_bygroup_lower, 1),
         impact_averted_upper = map(eeio_wta_averted_bygroup_upper, 1)) %>%
  unnest(cols = c(category, baseline, impact_averted, impact_averted_lower, impact_averted_upper))


# Deduct offsetting impacts from benefit ----------------------------------

equipment_cost_bygroup <- establishments_implementing_total %>%
  ungroup %>%
  filter(can_implement) %>%
  mutate(group = c('contracted foodservice operations', 'full-service restaurants', rep('limited-service restaurants, mobile foodservice, and bars', 2))) %>%
  group_by(group) %>%
  summarize(establishments = sum(n_estab)) %>%
  mutate(equipment_cost_lower = establishments * equipment_costs['lower'],
         equipment_cost_upper = establishments * equipment_costs['upper'])

# The three potential BEA industry codes to assign costs of equipment are:
# computer manufacturing, computer monitor and peripheral manufacturing, and the other machinery category which includes industrial and retail scales
industries_offset <- c('334111', '33411A', '33399A')

# Find the full names of the codes for the offsetting industries
industries_offset_codes <- all_codes$sector_desc_drc[match(industries_offset, all_codes$sector_code_uppercase)]

# Use the upper and lower bounds from the industries, and the upper and lower bounds for total cost, to get an upper and lower bound for the impact that is offset
# For each one, 3 costs * 3 offsetting industries
eeio_offsets_lower_bygroup <- map(equipment_cost_bygroup$equipment_cost_lower, 
                                     function(x) map(industries_offset_codes, ~ eeio_lcia('USEEIO2012', list(x), list(.))))
eeio_offsets_upper_bygroup <- map(equipment_cost_bygroup$equipment_cost_upper, 
                                     function(x) map(industries_offset_codes, ~ eeio_lcia('USEEIO2012', list(x), list(.))))            


# Within each list element, find the extreme value among the 3 offset industries
eeio_offsets_lower_bygroup_combined <- map(eeio_offsets_lower_bygroup, ~ apply(do.call(cbind, .), 1, min))
eeio_offsets_upper_bygroup_combined <- map(eeio_offsets_upper_bygroup, ~ apply(do.call(cbind, .), 1, max))

# Combine the results into a single data frame using list columns
eeio_offsets_range_bygroup <- equipment_cost_bygroup %>%
  mutate(category = map(eeio_offsets_lower_bygroup_combined, names),
         offset_lower = eeio_offsets_lower_bygroup_combined,
         offset_upper = eeio_offsets_upper_bygroup_combined) %>%
  unnest(cols = c(category, offset_lower, offset_upper))

# Join EEIO results for the impact reduction with EEIO results for the offset

eeio_dat_bygroup_withoffset <- eeio_dat_bygroup %>%
  left_join(eeio_offsets_range_bygroup)

# Combine everything
final_result_bygroup <- eeio_dat_bygroup_withoffset %>%
  mutate(percent_averted = signif(100 * impact_averted/baseline, 2),
         net_impact_averted_mean = impact_averted - (offset_lower + offset_upper) / 2,
         net_impact_averted_lower = impact_averted_lower - offset_upper,
         net_impact_averted_upper = impact_averted_upper - offset_lower,
         net_percent_averted_mean = 100 * net_impact_averted_mean/baseline,
         net_percent_averted_lower = 100 * net_impact_averted_lower/baseline,
         net_percent_averted_upper = 100 * net_impact_averted_upper/baseline) %>%
  filter(grepl('enrg|eutr|gcc|land|watr', category)) %>%
  mutate_at(vars(baseline, starts_with('impact_averted')), ~ . *  c(1e-9, 1e-6, 1e-9, 1e-10, 1e-9)) %>%
  mutate(category = rep(c('energy (PJ)', 'eutrophication (kT N)', 'greenhouse gas (MT CO2)', 'land (Mha)', 'water (km3)'), nrow(.)/5),
         total_cost_lower = cost_range['lower'] * establishments,
         total_cost_upper = cost_range['upper'] * establishments,
         cost_per_reduction_lower = total_cost_lower / net_impact_averted_upper,
         cost_per_reduction_upper = total_cost_upper / net_impact_averted_lower
  ) %>%
  mutate_at(vars(starts_with('net_impact_averted')), ~ . *  c(1e-9, 1e-6, 1e-9, 1e-10, 1e-9))

final_result_bygroup_display <- final_result_bygroup %>%
  select(group, category, cost_per_reduction_lower, cost_per_reduction_upper) %>%
  mutate(category = rep(c('energy ($/MJ)', 'eutrophication ($/kg N)', 'greenhouse gas ($/kg CO2)', 'land ($/m2)', 'water ($/m3)'), nrow(.)/5))

final_result_bygroup_tocsv <- eeio_dat_bygroup_withoffset %>%
  mutate(percent_averted = signif(100 * impact_averted/baseline, 2),
         net_impact_averted_lower = impact_averted_lower - offset_upper,
         net_impact_averted_mean = impact_averted - (offset_upper + offset_lower) / 2,
         net_impact_averted_upper = impact_averted_upper - offset_lower,
         net_percent_averted_mean = 100 * net_impact_averted_mean/baseline,
         net_percent_averted_lower = 100 * net_impact_averted_lower/baseline,
         net_percent_averted_upper = 100 * net_impact_averted_upper/baseline) %>%
  mutate(total_cost_lower = cost_range['lower'] * establishments,
         total_cost_mean = mean(cost_range) * establishments,
         total_cost_upper = cost_range['upper'] * establishments,
         cost_per_reduction_lower = total_cost_lower / net_impact_averted_upper,
         cost_per_reduction_mean = total_cost_mean / net_impact_averted_mean,
         cost_per_reduction_upper = total_cost_upper / net_impact_averted_lower)

# Save results
write_csv(final_result_bygroup, file.path(fp, 'scenario_results/interventions/eeio_wta_bysector_5categories_processed.csv'))
write_csv(final_result_bygroup_tocsv, file.path(fp, 'scenario_results/interventions/eeio_wta_bysector_all.csv'))
