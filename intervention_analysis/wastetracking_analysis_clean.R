# Clean version of waste tracking analysis (without plots and without Rmd)
# QDR / FWE / 18 Feb 2020


# Load data ---------------------------------------------------------------



# Load packages and check whether this is being run locally or on rstudio server.
library(tidyverse)
library(reticulate)
library(directlabels)

is_local <- dir.exists('Q:/')
fp <- ifelse(is_local, 'Q:', '/nfs/qread-data')
fp_github <- file.path(ifelse(is_local, '~/Documents/GitHub', '~'))

# Load numbers of establishments by NAICS
susb_naics <- read_csv(file.path(fp, 'csv_exports/SUSB_NAICS_allvariables.csv'))
# Load the BEA code data (erroneously called NAICS)
bea_codes <- read_csv(file.path(fp, 'crossreference_tables/naics_crosswalk_final.csv'))
# Load NAICS BEA crosswalks
load(file.path(fp, 'crossreference_tables/NAICS_BEA_SCTG_crosswalk.RData'))
bea_naics <- read_csv(file.path(fp, 'crossreference_tables/BEA_NAICS07_NAICS12_crosswalk.csv'))
# Load LAFA
source(file.path(fp_github, 'fwe/read_data/read_lafa.r'))
lafa <- list(dairy, fat, fruit, grain, meat, sugar, veg)


# Set assumptions ---------------------------------------------------------

cost_range <- c(lower = 8749, upper = 20102) # Lower and upper bounds for annual cost, based on percentiles for employee hourly wages.

waste_reduction <- c(lower = 0.4, upper = 0.5, mode = 0.45) # Waste reduction achievable, rates from ReFED?

prop_kitchen_waste <- c(lower = 0.7, upper = 0.97, mode = 0.85) # Proportion kitchen waste (all other than plate waste), estimated from a few sources

equipment_costs <- c(lower = 375, upper = 800) # Lower and upper bounds for annual equipment costs, based on 25% estimate from Steve and our existing assumptions for lower and upper bounds for total annual cost of equipment and fees combined. (rounded)

# Overall waste reduction is going to be the proportion kitchen waste reduction you can get from WTA * the proportion of food waste that is in the kitchen versus "plate waste" generated by the customers

# This is going to be the same for all. We will use the "mode"
overall_waste_reduction <- prop_kitchen_waste["mode"] * waste_reduction["mode"]


# Subsets of industries to target -----------------------------------------

codes_subset <- bea_codes %>% filter(stage %in% c('foodservice', 'institutional')) %>% select(BEA_389_code, BEA_389_def)

restaurants <- codes_subset$BEA_389_code[1:3]
tourism_hospitality <- codes_subset$BEA_389_code[c(4,6,9, 12, 14, 15, 16, 17, 18)] # Leave out movies and performances. Include air and ships.
institutions <- codes_subset$BEA_389_code[c(19, 20, 22:27)] # Leave out other educational services.

# 3 codes represent restaurants, 9 represent tourism/hospitality industry, 8 represent institutions that could adopt "WTA"

bea_to_use_df <- data.frame(BEA_Code = c(restaurants, tourism_hospitality, institutions),
                            sector = rep(c('restaurants', 'tourism and hospitality', 'institutions'), c(length(restaurants), length(tourism_hospitality), length(institutions))))

bea_naics_to_use <- bea_to_use_df %>% left_join(bea_naics)
# any(duplicated(bea_naics_to_use$related_2012_NAICS_6digit)) # There are no duplicates. 96 unique NAICS codes.

# Create subset with only food service.
susb_naics_foodservice <- bea_naics_to_use %>%
  select(BEA_Code, BEA_Title, sector, related_2012_NAICS_6digit) %>%
  rename(NAICS = related_2012_NAICS_6digit) %>%
  left_join(susb_naics)

# Flag rows that aren't going to be used (for example, freight transportation industries within transportation codes)
# Also remove campgrounds within the hospitality industry.
# unique(susb_naics_foodservice$`NAICS description`)
words_to_remove <- c('Freight', 'Nonscheduled', 'Air Traffic', 'Support Activities', 'Port', 'Cargo', 'Navigational', 'Towing', 'Packing', 'Campground')

susb_naics_foodservice <- susb_naics_foodservice %>%
  mutate(use = !grepl(paste(words_to_remove, collapse = '|'), `NAICS description`),
         `Size class` = factor(`Size class`, levels = c('fewer than 20', '20 to 99', '100 to 499', 'more than 500', 'total')))

# Find threshold of institution size to adopt WTA so that the volume of sales associated with establishments that adopt WTA 
# lines up with ReFED's assumptions that 80% of institutions and 15% of restaurants will adopt.

susb_food_sums <- susb_naics_foodservice %>% 
  group_by(sector, use, `Size class`) %>%
  summarize_at(vars(`No. firms`:`Total receipts`), sum) %>%
  filter(!is.na(`Size class`), !`Size class` %in% 'total')

# What are the proportions

susb_food_cumul_prop <- susb_food_sums %>%
  mutate_at(vars(`No. firms`:`Total receipts`), ~ cumsum(.x) / sum(.x))

# We can use 20 as the threshold. It can be altered.

size_classes_exclude <- expand_grid(sector = c('restaurants', 'tourism and hospitality', 'institutions'), `Size class` = levels(susb_food_sums$`Size class`)[1:4]) %>%
  mutate(exclude = `Size class` %in% c('fewer than 20'))

# Within each BEA code, get the percentage of total receipts that will be affected by WTA implementation
# All establishments with >20 employees, and also account for the fact that some tourism and hospitality BEA codes contain NAICS codes that aren't going to adopt WTA

susb_bea_food_sums <- susb_naics_foodservice %>%
  group_by(sector, BEA_Code, BEA_Title, use, `Size class`) %>%
  summarize_at(vars(`No. firms`:`Total receipts`), sum) %>%
  filter(!is.na(`Size class`), !`Size class` %in% 'total')


# Impute missing values ---------------------------------------------------

recbyestb <- susb_bea_food_sums %>%
  filter(use) %>%
  mutate(empl_per_firm = `No. employees`/`No. firms`,
         receipts_per_estb = `Total receipts`/`No. establishments`,
         receipts_per_firm = `Total receipts`/`No. firms`) 

# Impute the air transit number.
lm_air <- lm(log(receipts_per_firm) ~ log(empl_per_firm), data = recbyestb, subset = BEA_Title == 'Air transportation' & receipts_per_firm > 0)

predicted_air <- exp(predict(lm_air, newdata = recbyestb %>% filter(BEA_Title == 'Air transportation') %>% select(empl_per_firm)))
# predicted_air[4] # The imputed value for air transportation total receipts for firms with 500 or more employees.

# For water transportation, our problem is that we don't know either the average number of employees per firm or the receipts, the employees were
# also clearly censored wince only 202 employees for 11 firms is a lot less than 500 per firm. 
# Let's look for a similar industry to see whether we can get a number of employees per firm to use to impute.
lm_water <- lm(log(receipts_per_firm) ~ log(empl_per_firm), data = recbyestb, subset = BEA_Title == 'Water transportation' & receipts_per_firm > 0)

# We will use the number from scenic transportation (700) which seems fairly conservative
# This number can be sampled from in an uncertainty analysis too.
recbyestb %>% filter(BEA_Title == 'Water transportation') %>% mutate(empl_per_firm = if_else(`Size class` == 'more than 500', 700, empl_per_firm)) %>% select(empl_per_firm)
predicted_water <- exp(predict(lm_water, newdata = recbyestb %>% filter(BEA_Title == 'Water transportation') %>% mutate(empl_per_firm = if_else(`Size class` == 'more than 500', 700, empl_per_firm)) %>% select(empl_per_firm)))
exp(predict(lm_water))

# Create new imputed dataset.
susb_bea_food_sums[susb_bea_food_sums$BEA_Code %in% c('481000', '483000') & susb_bea_food_sums$use & susb_bea_food_sums$`Size class` %in% 'more than 500', "Total receipts"] <- c(predicted_air[4], predicted_water[4])


# Get final proportions affected ------------------------------------------

#### Here are the proportions of receipts that will be affected by adoption of WTA

susb_bea_proportion_affected <- susb_bea_food_sums %>% 
  ungroup %>%
  left_join(size_classes_exclude) %>%
  mutate(use = use & !exclude) %>%
  group_by(sector, BEA_Code, BEA_Title) %>%
  summarize(proportion_receipts_affected = sum(`Total receipts`[!exclude])/sum(`Total receipts`))

# Now multiply this by "proportion food" for each of the industries
prop_foods <- bea_codes %>%
  select(BEA_389_code, proportion_food) %>%
  rename(BEA_Code = BEA_389_code)

proportion_affected <- susb_bea_proportion_affected %>% left_join(prop_foods) %>% mutate(final_proportion = proportion_receipts_affected * proportion_food)

# We also need number of establishments affected so we can get the total annual cost
establishments_affected <- susb_bea_food_sums %>% 
  ungroup %>%
  left_join(size_classes_exclude) %>%
  mutate(use = use & !exclude) %>%
  group_by(sector, BEA_Code, BEA_Title, use) %>%
  summarize(establishments = sum(`No. establishments`))


# Load data for waste rate calc -------------------------------------------

# BEA levels 1+3 to 4+6+7+8 is already subsetted from an older analysis I did.
food_U <- read.csv(file.path(fp, 'crossreference_tables/level13_to_level4678_inputs.csv'), row.names = 1, check.names = FALSE)

# Mapping will need to go bea --> qfahpd --> lafa
# Load the two necessary crosswalks.
bea2qfahpd <- read_csv(file.path(fp, 'crossreference_tables/bea_qfahpd_crosswalk.csv'))
qfahpd2lafa <- read_csv(file.path(fp, 'crossreference_tables/qfahpd_lafa_crosswalk.csv'))

# Also load the QFAHPD data so that we can get the prices.
qfahpd2 <- read_csv(file.path(fp, 'raw_data/USDA/QFAHPD/tidy_data/qfahpd2.csv'))

# Read the description of LAFA's nested category structure in.
lafa_struct <- read_csv(file.path(fp, 'crossreference_tables/lafa_category_structure.csv'))

# Demand codes table to convert 6 digit codes to the ones used by USEEIO
all_codes <- read_csv(file.path(fp, 'crossreference_tables/all_codes.csv'))

# Get rid of unneeded rows and columns
food_U <- food_U[, proportion_affected$BEA_Code]
food_U <- food_U[rowSums(food_U) > 0, ]

# Beverage codes should be removed.
beveragecodes <- c('311920','311930','312110','312120','312130','312140')
food_U <- food_U[!row.names(food_U) %in% beveragecodes, ]


# Map BEA to QFAHPD -------------------------------------------------------

# Convert the comma-separated string columns to list columns.
bea2qfahpd <- bea2qfahpd %>%
  mutate(QFAHPD_code = strsplit(QFAHPD_code, ';'))
qfahpd2lafa <- qfahpd2lafa %>%
  mutate(LAFA_names = strsplit(LAFA_names, ';'))

# Do the mapping of food_U to QFAHPD codes.
food_U_QFAHPD <- food_U %>%
  mutate(BEA_389_code = row.names(food_U)) %>%
  pivot_longer(-BEA_389_code, names_to = 'BEA_recipient_code', values_to = 'monetary_flow') %>%
  left_join(bea2qfahpd %>% select(-BEA_389_def)) %>%
  group_by(BEA_389_code, BEA_recipient_code) %>%
  group_modify(~ data.frame(QFAHPD_code = .$QFAHPD_code[[1]], monetary_flow = .$monetary_flow/length(.$QFAHPD_code[[1]])))

# Now we have the use table where each BEA code has multiple rows for the different QFAHPD codes that make it up
# Create an aggregated version of QFAHPD to get the final price values for each code
# Weighted average across all market groups, years, and quarters
qfahpd_agg <- qfahpd2 %>%
  group_by(foodgroup) %>%
  summarize(price = weighted.mean(price, aggweight, na.rm = TRUE))

# Join the aggregated QFAHPD back up with its numerical codes and LAFA names
# Meanwhile correct a couple wrong names in the dairy category
qfahpd_agg <- qfahpd_agg %>% 
  mutate(foodgroup = gsub('Whole and 2%', 'Regular fat', foodgroup)) %>%
  left_join(qfahpd2lafa, by = c('foodgroup' = 'QFAHPD_name')) %>%
  mutate(QFAHPD_code = as.character(QFAHPD_code))

# Now join the aggregated QFAHPD with the food_U mapped to QFAHPD so that the total $ can be divided by $/weight to yield a weight (or mass).
# The units mass is in don't matter since they are all relative
food_U_LAFA <- food_U_QFAHPD %>%
  left_join(qfahpd_agg) %>%
  mutate(mass_flow = monetary_flow / price)


# Get LAFA rates including lower-level averages ---------------------------

# For the unique LAFA names in the QFAHPD to LAFA mapping, extract the waste rates for 2012 or the closest year post-2012.
lafa_to_extract <- Reduce(union, qfahpd2lafa$LAFA_names)

# Split it up again by LAFA so that we can get the weights.
# Get only the columns we care about from each LAFA element in the list
# Then get the year closest to 2012
lafa_df <- lafa %>% 
  map_dfr(~ select(., Category, Year, Loss_at_consumer_level_Other__cooking_loss_and_uneaten_food__Percent, Consumer_weight_Lbs.year)) %>%
  rename(avoidable_consumer_loss = Loss_at_consumer_level_Other__cooking_loss_and_uneaten_food__Percent,
         consumer_weight = Consumer_weight_Lbs.year) %>%
  filter(!is.na(avoidable_consumer_loss)) %>%
  group_by(Category) %>%
  summarize(avoidable_consumer_loss = avoidable_consumer_loss[which.min(abs(Year-2012))],
            consumer_weight = consumer_weight[which.min(abs(Year-2012))])

# Use nested category structure to get weighted mean rates for the coarser LAFA groups
# for QFAHPD foods that do not resolve to the finest available level of LAFA
lafa_df <- lafa_df %>%
  left_join(lafa_struct, by = c('Category' = 'Food'))

lafa_group_rates <- map_dfr(1:4, function(i) lafa_df %>% 
                              rename_(subgroup = paste0('subgroup', i)) %>%
                              group_by(subgroup) %>% 
                              summarize(avoidable_consumer_loss = weighted.mean(x = avoidable_consumer_loss, w = consumer_weight))) %>%
  filter(!is.na(subgroup))

# Use LAFA overall mean for prepared food in the "other" category
overall_mean <- with(lafa_df, weighted.mean(avoidable_consumer_loss, consumer_weight))

all_lafa_rates <- data.frame(Category = c(lafa_df$Category, lafa_group_rates$subgroup, 'prepared food'),
                             avoidable_consumer_loss = c(lafa_df$avoidable_consumer_loss, lafa_group_rates$avoidable_consumer_loss, overall_mean))


# Map mass flows to LAFA, convert back to $ -------------------------------

# Use the same pipe as last time to spread out the LAFA names over the rows

food_U_LAFA_spread <- food_U_LAFA %>%
  group_by(BEA_389_code, BEA_recipient_code, QFAHPD_code, price) %>%
  group_modify(~ data.frame(LAFA_name = .$LAFA_names[[1]], 
                            mass_flow = .$mass_flow/length(.$LAFA_names[[1]]),
                            monetary_flow = .$monetary_flow/length(.$LAFA_names[[1]]))) %>%
  left_join(all_lafa_rates, by = c('LAFA_name' = 'Category'))

# Join with the proportion of sales affected (also the same as proportion of mass affected) based on % sales that are food and the >20 employee threshold
# Then calculate the reduction in required mass flow for each food type, and then a weighted average to get the reduction in monetary flow needed
demand_change_fn <- function(W0, r, p) p * ((1 - W0) / (1 - (1 - r) * W0) - 1) + 1

food_U_LAFA_spread <- food_U_LAFA_spread %>% 
  left_join(proportion_affected, by = c('BEA_recipient_code' = 'BEA_Code')) %>%
  mutate(reduction_by_mass = demand_change_fn(W0 = avoidable_consumer_loss/100, r = overall_waste_reduction, p = proportion_receipts_affected),
         mass_flow_post_intervention = mass_flow * reduction_by_mass,
         monetary_flow_post_intervention = mass_flow_post_intervention * price)

# Sum up by old row and column index from the original food_U matrix, then reshape to make the same matrix.
food_U_postintervention_df <- food_U_LAFA_spread %>%
  group_by(BEA_389_code, BEA_recipient_code) %>%
  summarize(monetary_flow = sum(monetary_flow_post_intervention, na.rm = TRUE)) 

food_U_postintervention <- food_U_postintervention_df %>%
  pivot_wider(names_from = BEA_recipient_code, values_from = monetary_flow, values_fill = list(monetary_flow = 0)) %>%
  as.data.frame
row.names(food_U_postintervention) <- food_U_postintervention$BEA_389_code
food_U_postintervention <- food_U_postintervention[, !names(food_U_postintervention) %in% 'BEA_389_code']

# Make the row and column order the same as food_U
food_U_postintervention <- food_U_postintervention[, names(food_U)]


# Summarize $ and mass flow changes ---------------------------------------

# The % of waste reduced by mass won't be exactly equivalent to the % of waste reduced by $.

postintervention <- food_U_postintervention_df %>%
  group_by(BEA_recipient_code) %>%
  summarize(monetary_flow_postintervention = sum(monetary_flow))

preintervention <- data.frame(BEA_recipient_code = names(food_U), monetary_flow_preintervention = colSums(food_U))

monetary_byintervention <- left_join(postintervention, preintervention) %>%
  mutate(reduction_bydollar = 1 - monetary_flow_postintervention / monetary_flow_preintervention) 

mass_byintervention <- food_U_LAFA_spread %>%
  group_by(BEA_recipient_code) %>%
  summarize(mass_flow_preintervention = sum(mass_flow, na.rm = TRUE),
            mass_flow_postintervention = sum(mass_flow_post_intervention, na.rm = TRUE)) %>%
  mutate(reduction_bymass = 1 - mass_flow_postintervention / mass_flow_preintervention) 

rate_changes <- left_join(mass_byintervention, monetary_byintervention)

# A better way is to phrase it as reducing the operating costs (purchases of raw materials) by the affected industries
# Since we have a waste rate reduction by mass, convert it back to waste rate reduction by money and get the purchasing rate reduction from each of the industries that supply the final foodservice industries.

# Calculate pre and post incoming monetary food flow in millions of dollars
total_prepost <- data.frame(BEA_Code = names(food_U),
                            food_purchases_baseline = colSums(food_U),
                            food_purchases_postintervention = colSums(food_U_postintervention)) %>%
  mutate(reduction = food_purchases_baseline - food_purchases_postintervention)


# Calculate baseline waste by industry ------------------------------------

# Weighted mean of waste rate by mass flow for each foodservice industry = final waste rate for the industries!
baseline_waste_foodservice <- food_U_LAFA_spread %>%
  group_by(BEA_recipient_code) %>%
  summarize(avoidable_consumer_loss = weighted.mean(x = avoidable_consumer_loss, w = mass_flow, na.rm = TRUE))

# Join up the names of the BEA codes and print the table of values
baseline_waste_foodservice <- baseline_waste_foodservice %>% 
  left_join(codes_subset, by = c('BEA_recipient_code' = 'BEA_389_code')) %>%
  setNames(c('BEA_Code', 'baseline', 'BEA_Title')) %>%
  left_join(bea_to_use_df)

baseline_waste_foodservice <- baseline_waste_foodservice %>%
  left_join(proportion_affected %>% select(BEA_Code, proportion_receipts_affected, proportion_food)) %>%
  left_join(total_prepost)

# Above they were marginal column totals for the recipient industries
# Phrase it also as marginal row totals for the food types

reduction_byfoodtype <- data.frame(BEA_Code = row.names(food_U),
                                   cost_averted = rowSums(food_U) - rowSums(food_U_postintervention))


# Run EEIO ----------------------------------------------------------------

# Simply enough, just run it on the difference in the two rowSums for pre and post intervention
# This represents final operating costs of the industries, as if it were final consumer demand
if (!is_local) use_python('/usr/bin/python3')
source_python(file.path(fp_github, 'fwe/USEEIO/eeio_lcia.py'))

# The model is already built so we don't need to build it again. 
# All we need to do is match the demand vector 6 digit codes with the codes that include the full names
# then run eeio_lcia on it.

demand_vector <- reduction_byfoodtype %>%
  left_join(all_codes, by = c('BEA_Code' = 'sector_code_uppercase')) %>%
  with(list(codes = sector_desc_drc, values = cost_averted))

eeio_wta <- eeio_lcia('USEEIO2012', demand_vector$values * 1e6, demand_vector$codes) 

# Also do for the baseline
baseline_byfoodtype <- data.frame(BEA_Code = row.names(food_U),
                                  baseline = rowSums(food_U))

demand_vector_baseline <- baseline_byfoodtype %>%
  left_join(all_codes, by = c('BEA_Code' = 'sector_code_uppercase')) %>%
  with(list(codes = sector_desc_drc, values = baseline))

eeio_wta_baseline <- eeio_lcia('USEEIO2012', demand_vector_baseline$values * 1e6, demand_vector_baseline$codes) 

# A table is probably the best way to show it
eeio_dat <- data.frame(category = row.names(eeio_wta),
                       baseline = eeio_wta_baseline$Total,
                       impact_averted = eeio_wta$Total)

# For display
eeio_dat %>%
  filter(grepl('enrg|eutr|gcc|land|watr', category)) %>%
  mutate(baseline = baseline * c(1e-9, 1e-6, 1e-9, 1e-10, 1e-9),
         impact_averted = impact_averted * c(1e-9, 1e-6, 1e-9, 1e-10, 1e-9),
         category = c('energy (PJ)', 'eutrophication (kT N)', 'greenhouse gas (MT CO2)', 'land (Mha)', 'water (km3)'),
         percent_averted = signif(100 * impact_averted/baseline, 2))


# Deduct offsetting impacts from benefit ----------------------------------

# Number of establishments that need to adopt intervention
n_estab <- sum(establishments_affected$establishments[establishments_affected$use])

# The three potential BEA industry codes to assign costs of equipment are:
# computer manufacturing, computer monitor and peripheral manufacturing, and the other machinery category which includes industrial and retail scales
industries_offset <- c('334111', '33411A', '33399A')
total_equipment_cost <- equipment_costs * n_estab # 167M to 357M

# Use the mean of the two for now
mean_total_equipment_cost <- mean(total_equipment_cost)

# Find the full names of the codes for the offsetting industries
industries_offset_codes <- all_codes$sector_desc_drc[match(industries_offset, all_codes$sector_code_uppercase)]

eeio_offsets <- map(industries_offset_codes, ~ eeio_lcia('USEEIO2012', list(mean_total_equipment_cost), list(.)))

# Use the upper and lower bounds from the industries, and the upper and lower bounds for total cost, to get an upper and lower bound for the impact that is offset

eeio_offsets_lower <- map(industries_offset_codes, ~ eeio_lcia('USEEIO2012', list(total_equipment_cost['lower']), list(.)))
eeio_offsets_upper <- map(industries_offset_codes, ~ eeio_lcia('USEEIO2012', list(total_equipment_cost['upper']), list(.)))

eeio_offsets_df <- rbind(data.frame(category = row.names(eeio_offsets_lower[[1]]), do.call(cbind, eeio_offsets_lower) %>% setNames(industries_offset_codes), bound = 'lower'),
                         data.frame(category = row.names(eeio_offsets_upper[[1]]), do.call(cbind, eeio_offsets_upper) %>% setNames(industries_offset_codes), bound = 'upper'))

eeio_offsets_range <- eeio_offsets_df %>%
  pivot_longer(cols = -c(category, bound)) %>%
  group_by(category) %>%
  group_modify(~ data.frame(offset_lower = min(.$value), offset_upper = max(.$value)))

# Final result with offset
eeio_dat_with_offset <- eeio_dat %>%
  left_join(eeio_offsets_range) %>%
  mutate(net_impact_averted_lower = impact_averted - offset_upper,
         net_impact_averted_upper = impact_averted - offset_lower) %>%
  filter(grepl('enrg|eutr|gcc|land|watr', category)) 

# For display
eeio_dat_with_offset %>%
  mutate_at(vars(baseline:net_impact_averted_upper), ~ . * c(1e-9, 1e-6, 1e-9, 1e-10, 1e-9)) %>%
  mutate(net_percent_averted_lower = 100 * net_impact_averted_lower/baseline,
         net_percent_averted_upper = 100 * net_impact_averted_upper/baseline,
         category = c('energy (PJ)', 'eutrophication (kT N)', 'greenhouse gas (MT CO2)', 'land (Mha)', 'water (km3)')) %>%
  select(-baseline, -impact_averted) %>%
  mutate_if(is.numeric, ~ signif(., 3))


# Compare cost and environmental benefit ----------------------------------

total_cost <- cost_range * n_estab # 4 to 9 billion

cost_per_impact <- eeio_dat_with_offset %>%
  filter(grepl('enrg|eutr|gcc|land|watr', category)) %>%
  mutate(cost_per_reduction_lower = total_cost[1] / net_impact_averted_upper,
         cost_per_reduction_upper = total_cost[2] / net_impact_averted_lower)

final_result <- cost_per_impact %>%
  select(-impact_averted, -baseline) %>%
  mutate(category = c('energy ($/MJ)', 'eutrophication ($/kg N)', 'greenhouse gas ($/kg CO2)', 'land ($/m2)', 'water ($/m3)'),
         cost_per_reduction_lower = paste0('$', round(cost_per_reduction_lower, 2)),
         cost_per_reduction_upper = paste0('$', round(cost_per_reduction_upper, 2)))
